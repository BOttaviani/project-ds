{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:///home/user/Documents/RCP-216/myopennlp.jar\n",
      "Finished download of myopennlp.jar\n"
     ]
    }
   ],
   "source": [
    "import sys.process._\n",
    "%AddJar file:///home/user/Documents/RCP-216/myopennlp.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "//CONTEXTE DE TRAVAIL\n",
    "import fllemmatizer.FLLemmatizer\n",
    "import scala.collection.JavaConversions._\n",
    "import scala.io.Source    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|      mot|frequence|\n",
      "+---------+---------+\n",
      "|     recu|        6|\n",
      "|    chien|        5|\n",
      "|      ces|      148|\n",
      "| rehaussé|        1|\n",
      "|  agencée|       11|\n",
      "|correpond|        2|\n",
      "|    those|        2|\n",
      "|   voyage|      129|\n",
      "|  sorties|       26|\n",
      "| d'emblée|        3|\n",
      "+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "[Stage 8:================================================>      (178 + 4) / 200]+-------+------------------+\n",
      "|summary|         frequence|\n",
      "+-------+------------------+\n",
      "|  count|             19353|\n",
      "|   mean|26.163643879501887|\n",
      "| stddev|322.48316214763656|\n",
      "|    min|                 1|\n",
      "|    max|             19042|\n",
      "+-------+------------------+\n",
      "\n",
      "+-----------+---------+                                                         \n",
      "|        mot|frequence|\n",
      "+-----------+---------+\n",
      "|       très|    13886|\n",
      "|        est|    10351|\n",
      "|   positif$|     8640|\n",
      "|       pour|     7157|\n",
      "|       nous|     6912|\n",
      "|       bien|     6734|\n",
      "|        pas|     5249|\n",
      "|        les|     5153|\n",
      "|       dans|     4970|\n",
      "|appartement|     4217|\n",
      "+-----------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/nounDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/nounDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/adjDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/adjDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/advDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/verbDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/advDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/verbDic.txt\n",
      "[Stage 14:>                                                         (0 + 2) / 2][INFO]: Load dictionary : ressources/dictionaries/fr/detDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/pronounDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/detDic.txt\n",
      "[INFO]: Load dictionary : ressources/dictionaries/fr/pronounDic.txt\n",
      "[Stage 29:==================================================>   (188 + 4) / 200]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "echantillon = [Id_comment: string, commentaire: string ... 1 more field]\n",
       "commentaires_lus = [msg: string]\n",
       "evaluationRDD = Data/Evaluation_V4 MapPartitionsRDD[39] at textFile at <console>:61\n",
       "evaluation_poids_brut = [expression: string, poids: string]\n",
       "evaluation_poids = [expression: string, poids: string]\n",
       "evaluation_filtree = MapPartitionsRDD[53] at mapPartitions at <console>:73\n",
       "evaluation_lemmatisee = [mot: string]\n",
       "mots_evaluation = [mot: string]\n",
       "commentaires_filtres = [msg: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n",
       "commentaires: org....\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[msg: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "//LECTURE DU FICHIER D'ENTREE DE L'ECHANTILLON DE COMMENTAIRES EVALUES\n",
    "val echantillon = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Data/echantillon_evalue.csv\")\n",
    "\n",
    "//CREATION DE LA TABLE ASSOCIEE A L'ECHANTILLON\n",
    "echantillon.createOrReplaceTempView(\"echantillon\")\n",
    "\n",
    "//RE-STRUCTURATION DE L'ECHANTILLON D'APPRENTISSAGE POUR INTEGRER LA QUALITE DANS LE COMMENTAIRE\n",
    "val commentaires_lus = spark.sql(\"select concat( qualite, '$ ', commentaire, ' ')  as msg from echantillon\")\n",
    "\n",
    "//CREATION DE LA TABLE DES COMMENTAIRES LUS\n",
    "commentaires_lus.createOrReplaceTempView(\"commentaires_lus\")\n",
    "\n",
    "//LECTURE DU FICHIER D'ENTREE DES EVALUATIONS\n",
    "val evaluationRDD = sc.textFile(\"Data/Evaluation_V4\")\n",
    "\n",
    "//LECTURE DU FICHIER DES EVALUATION PONDEREES\n",
    "val evaluation_poids_brut = spark.read.option(\"delimiter\", \"#\").csv(\"Data/Evaluation_V4\").toDF(\"expression\", \"poids\")\n",
    "\n",
    "//REFORMATAGE DU CONTENU DE LA COLONNE \"EXPRESSION\" DU FICHIER DES EVALUATIONS PONDEREES\n",
    "val evaluation_poids = evaluation_poids_brut.rdd.map(x => (x.getAs[String](0).replace(\"%\",\"\").replace(\" \",\"\"),x.getAs[String](1))).toDF(\"expression\",\"poids\")\n",
    "\n",
    "//CREATION DE LA TABLE DES EVALUATIONS PONDEREES\n",
    "evaluation_poids.createOrReplaceTempView(\"evaluation_poids\")\n",
    "\n",
    "//APPLICATION DU LEMMATISEUR FRANCAIS A CHAQUE MOT DE CHAQUE COMMENTAIRE DE L'ECHANTILLON, PUIS FILTRAGE\n",
    "val evaluation_filtree :org.apache.spark.rdd.RDD[String] = evaluationRDD.mapPartitions(iter => {\n",
    "                                        val lemmatizer = new FLLemmatizer(\"fr\");\n",
    "                                        iter.map{s => lemmatizer.lemmatize(s, true).filter(s =>s(1) == \"NOUN\"|| s(1) == \"ADJ\").map(s => s(2)).toString};\n",
    "                                       })\n",
    "\n",
    "//MISE AU FORMAT DATAFRAME APRES ELIMINATION DES CARACTERES INDESIRABLES\n",
    "val evaluation_lemmatisee = evaluation_filtree.map(x => x.toString.replace(\"ArrayBuffer(\",\"\").replace(\")\",\"\").replace(\",\",\"\")).toDF(\"mot\")\n",
    "evaluation_lemmatisee.createOrReplaceTempView(\"evaluation_lemmatisee\")\n",
    "val mots_evaluation = spark.sql(\"select distinct mot from evaluation_lemmatisee where mot <> ''\")\n",
    "mots_evaluation.createOrReplaceTempView(\"Mots_evaluation\")\n",
    "\n",
    "//FILTRAGE DES COMMENTAIRES VIDES\n",
    "val commentaires_filtres = spark.sql(\"select * from commentaires_lus where msg is not null\")\n",
    "\n",
    "//REFORMATAGE DES COMMENTAIRES LUS => TOUS LES CARACTERES SONT MIS EN LETTRES MINUSCULES\n",
    "val commentaires = commentaires_filtres.rdd.map(x => x.getAs[String](0).toLowerCase).toDF(\"commentaire\")\n",
    "\n",
    "//DECOUPAGE DES COMMENTAIRES EN MOTS\n",
    "val motsCommentaires = commentaires.select(\"commentaire\").rdd.map(x => x.getAs[String](0)\n",
    "                                                                        .replace(\"positfs$\",\"\")\n",
    "                                                                        .replace(\"negatfs$\",\"\")\n",
    "                                                                        .replace(\",\",\"\")\n",
    "                                                                        .replace(\";\",\"\"))\n",
    "                                                         .flatMap(line => line.split(\" \")).toDS\n",
    "\n",
    "//COMPTAGE DES MOTS DANS L'ENSEMBLE DES COMMENTAIRES\n",
    "val motsOccurrences = motsCommentaires.groupByKey(identity).count().toDF(\"mot\", \"frequence\")\n",
    "\n",
    "//CREATION DE LA TABLE SQL DES MOTS\n",
    "motsOccurrences.createOrReplaceTempView(\"Mots_echantillon\")\n",
    "\n",
    "//VISUALISATION DE LA TABLE DES MOTS\n",
    "motsOccurrences.show(10)\n",
    "\n",
    "//STATISTIQUES ELEMENTAIRES\n",
    "motsOccurrences.select(\"frequence\").describe().show\n",
    "\n",
    "//LES 10 MOTS SIGNIFICATIFS LES PLUS COURANTS\n",
    "spark.sql(\"select mot, frequence from Mots_echantillon where mot <> '' and length(mot) > 2 order by frequence desc\").show(10)\n",
    "\n",
    "//JOINTURE ENTRE ECHANTILLON ET EVALUATION\n",
    "val comptage_mots = spark.sql(\"select a.mot, b.frequence from Mots_evaluation a inner join Mots_echantillon b on b.mot = a.mot where length(a.mot) > 3 and a.mot <> 'point' order by frequence desc\")\n",
    "comptage_mots.createOrReplaceTempView(\"comptage_mots\")\n",
    "\n",
    "//JOINTURE POUR RAJOUTER LA QUALITE\n",
    "val comptage_mots_poids = spark.sql(\"select distinct a.frequence, a.mot, b.poids from comptage_mots a , evaluation_poids b where a.mot = b.expression order by a.frequence desc\")\n",
    "comptage_mots_poids.createOrReplaceTempView(\"comptage_mots_poids\")\n",
    "\n",
    "val comptage_mots_qualite = spark.sql(\"select cast(5*sqrt(frequence) as Int) as frequence, mot, case when poids > 0 then 1 else 0 end as qualite from comptage_mots_poids\")\n",
    "\n",
    "val comptage_mots_qualiteRDD = comptage_mots_qualite.rdd.map(r => r.toString).map(r => r.replace(\",\",\" \"))\n",
    "\n",
    "val nuage_mots = comptage_mots_qualiteRDD.toDF.rdd.map(x => x.getAs[String](0).replace(\"[\",\"\").replace(\"]\",\"\")).toDF\n",
    "\n",
    "//SAUVEGARDE DE LA TABLE\n",
    "nuage_mots.rdd.map(x => x.toString.replace(\"[\",\"\").replace(\"]\",\"\")).coalesce(1).saveAsTextFile(\"nuage_mots\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
