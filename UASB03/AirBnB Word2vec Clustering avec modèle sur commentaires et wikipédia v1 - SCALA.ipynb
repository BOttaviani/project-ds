{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.rdd._\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.mllib.feature.{Word2Vec, Word2VecModel}\n",
    "import org.apache.spark.mllib.linalg.{Vector, Vectors, DenseVector, SparseVector}\n",
    "import org.apache.spark.mllib.clustering.KMeans\n",
    "import org.apache.spark.mllib.util.KMeansDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import breeze.linalg.{DenseVector=>BDV, SparseVector=>BSV, Vector=>BV}\n",
       "import org.apache.spark.mllib.linalg.{Vector=>SparkVector}\n",
       "toBreeze: (v: org.apache.spark.mllib.linalg.Vector)breeze.linalg.Vector[Double]\n",
       "fromBreeze: (bv: breeze.linalg.Vector[Double])org.apache.spark.mllib.linalg.Vector\n",
       "add: (v1: org.apache.spark.mllib.linalg.Vector, v2: org.apache.spark.mllib.linalg.Vector)org.apache.spark.mllib.linalg.Vector\n",
       "scalarMultiply: (a: Double, v: org.apache.spark.mllib.linalg.Vector)org.apache.spark.mllib.linalg.Vector\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import breeze.linalg.{DenseVector => BDV, SparseVector => BSV, Vector => BV}\n",
    "import org.apache.spark.mllib.linalg.{Vector => SparkVector}\n",
    "def toBreeze(v:SparkVector) = BV(v.toArray)\n",
    "def fromBreeze(bv:BV[Double]) = Vectors.dense(bv.toArray)\n",
    "def add(v1:SparkVector, v2:SparkVector) = fromBreeze(toBreeze(v1) + toBreeze(v2))\n",
    "def scalarMultiply(a:Double, v:SparkVector) = fromBreeze(a * toBreeze(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:=============================>                             (2 + 2) / 4]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stopWords = Set(pres, afin, est, duquel, celui-là, dos, precisement, e, se, seras, combien, differents, tiens, le, tellement, aient, soixante, des, directe, nommés, desquels, s, hou, quatre, tout, ceux-ci, encore, chez, unes, aurons, peux, premier, relative, votre, auras, quant, bigre, x, onze, laquelle, ollé, merci, eusse, toute, du, fais, vous-mêmes, entre, sapristi, dix, avec, serez, était, cinquantième, moi, peuvent, ta, tien, parfois, cher, fut, vôtres, suis, nôtres, tel, remarquable, mon, clic, bat, ho, parmi, dans, dernier, dès, oh, différentes, hein, force, lès, soient, façon, neanmoins, clac, celles, allons, reste, hem, parce, treize, êtes, ayant, juste, nouveaux, sois, toujours, olé, tardive, ouste, vé, faites, eu,...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Set(pres, afin, est, duquel, celui-là, dos, precisement, e, se, seras, combien, differents, tiens, le, tellement, aient, soixante, des, directe, nommés, desquels, s, hou, quatre, tout, ceux-ci, encore, chez, unes, aurons, peux, premier, relative, votre, auras, quant, bigre, x, onze, laquelle, ollé, merci, eusse, toute, du, fais, vous-mêmes, entre, sapristi, dix, avec, serez, était, cinquantième, moi, peuvent, ta, tien, parfois, cher, fut, vôtres, suis, nôtres, tel, remarquable, mon, clic, bat, ho, parmi, dans, dernier, dès, oh, différentes, hein, force, lès, soient, façon, neanmoins, clac, celles, allons, reste, hem, parce, treize, êtes, ayant, juste, nouveaux, sois, toujours, olé, tardive, ouste, vé, faites, eu, relativement, comparables, pièce, quelque, dit, floc, pff, n, dits, vos, importe, eus, exactement, tu, cinq, notamment, delà, eûmes, voient, quels, celui, qui, suivante, celà, jusque, restrictif, celle, mine, seraient, cette, ça, toutefois, autre, mes, different, diverses, toi, tenant, elle-même, par, debout, si, essai, aurions, moi-meme, j, y, apres, suivants, huitième, semblent, retour, aujourd'hui, desormais, nôtre, lorsque, dixième, serons, auxquelles, las, particulier, miennes, sont, troisième, parseme, etc, abord, celles-là, pif, fussions, alors, particulièrement, t, certains, suivant, sur, jusqu, permet, eue, quiconque, suivantes, sujet, dring, u, une, aviez, moi-même, devra, nombreuses, aujourd, superpose, doivent, sauf, pire, f, huit, allô, egale, diverse, seriez, quand, holà, soit, chère, hors, mienne, ouvert, semblable, onzième, pfft, hum, douzième, ore, differentes, même, auront, auriez, avait, avant, sinon, uniformement, chaque, a, eues, dont, puis, depuis, ceux-là, fussent, uns, nous, probable, pur, nombreux, dix-huit, ayez, mêmes, tous, voilà, quant-à-soi, désormais, lors, la, à, quanta, pendant, quel, strictement, as, uniques, fût, avoir, mince, ton, eusses, vont, basee, ait, m, car, plusieurs, vu, soi, hop, touchant, certain, mot, proche, être, malgré, miens, restent, parle, certaines, pourrais, souvent, avez, beaucoup, hue, pure, pouvait, naturel, étées, suit, particulière, eut, probante, chacune, mien, eût, possibles, voici, et, serai, ouf, aurais, multiples, de, aussi, ma, stop, va, tenir, dire, i, ô, fûtes, sein, specifique, autrement, etre, elles, vingt, attendu, ha, hep, concernant, quatorze, aies, tienne, plouf, valeur, leur, premièrement, mille, toutes, nul, tandis, hélas, necessairement, eussions, quelques, ah, hui, zut, deja, devrait, mais, je, quoi, surtout, effet, vif, moyennant, maintenant, tic, directement, septième, vers, trois, comme, fois, font, ses, eurent, ces, après, v, trente, étiez, parlent, étais, pourquoi, près, rarement, seul, doit, laisser, six, été, différents, soyons, naturelle, restant, tsoin, lui, allo, quelconque, moindres, tac, étions, partant, quoique, quinze, lequel, brrr, tente, egales, divers, aux, ce, quatrièmement, avons, soyez, boum, revoici, q, on, pourrait, néanmoins, ni, devant, cinquième, longtemps, pour, da, son, b, rien, fusses, différent, ès, aura, ayons, dehors, crac, vives, auraient, allaient, compris, ils, auxquels, procedant, g, lesquelles, tsouin, anterieur, nouveau, furent, là, autrefois, celles-ci, chères, tend, houp, rare, celui-ci, ainsi, l, prealable, donc, me, vôtre, malgre, aurait, outre, serions, ceux, vous, en, tant, il, étés, speculatif, exterieur, â, suffit, sienne, comment, via, memes, maint, necessaire, personne, eussiez, haut, p, ouias, revoilà, suivre, absolument, fait, autrui, troisièmement, aurai, deuxième, feront, suffisante, un, eûtes, na, quelqu'un, ai, siens, les, durant, elle, sous, vlan, meme, passé, es, quatrième, quelle, tels, minimale, fûmes, serait, vais, derrière, seule, plupart, specifiques, douze, gens, seulement, sent, quelles, hi, ci, couic, vas, semble, autres, te, etant, subtiles, comparable, chut, té, au, ohé, soi-même, lui-meme, toc, dedans, tes, seront, contre, ailleurs, sien, siennes, aie, cet, parler, desquelles, qu, hé, o|, notre, pu, dessus, c, dite, certes, pouah, psitt, pfut, première, aurez, nous-mêmes, dix-neuf, flac, telles, possessif, ouverts, tiennes, oust, h, étant, lui-même, deuxièmement, quarante, puisque, multiple, enfin, celle-là, semblaient, assez, r, eh, vivat, aupres, maximale, sa, rares, fussiez, plein, w, voie, devers, eux-mêmes, cela, fi, différente, lesquels, sait, toi-même, que, peut, sommes, eussent, environ, état, chers, telle, paf, selon, rendre, pense, anterieures, fus, ne, egalement, fusse, eux, derniere, personnes, pan, auquel, où, hurrah, plutôt, extenso, k, dessous, étée, certaine, ou, derriere, ici, bah, euh, suffisant, cinquantaine, ceci, seize, unique, quatre-vingt, neuvième, possible, chacun, étaient, faisaient, celle-ci, droite, sacrebleu, cinquante, naturelles, vive, début, non, cependant, avais, bas, rend, dix-sept, hormis, anterieure, serais, parole, ont, o, avaient, ouverte, envers, avions, sept, faisant, z, possessifs, leurs, sera, nos, vifs, elles-mêmes, cent, chiche, excepté, sixième, deux, d)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// lire les stop words\n",
    "import scala.io.Source\n",
    "val stopWords = Source.fromFile(\"/home/user/Documents/UASB03/AirBnBStopwords-fr.txt\").getLines.toSet\n",
    "\n",
    "// transmettre les stop words aux noeuds de calcul\n",
    "val bStopWords = sc.broadcast(stopWords)\n",
    "\n",
    "// lire le Word2VecModel\n",
    "val w2vModel = Word2VecModel.load(sc, \"modele/Word2VecFR\")\n",
    "\n",
    "// obtenir une Map[String, Array[Float]] sérializable\n",
    "//   mapValues seul ne retourne pas une map sérializable (SI-7005)\n",
    "val vectors = w2vModel.getVectors.mapValues(vv => Vectors.dense(vv.map(_.toDouble))).map(identity)\n",
    "\n",
    "// transmettre la map aux noeuds de calcul\n",
    "val bVectors = sc.broadcast(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vectSize = 100\n",
       "sentences = /home/user/Documents/UASB03/comment_fr_filtre.csv MapPartitionsRDD[8] at textFile at <console>:58\n",
       "sent2vec = MapPartitionsRDD[12] at filter at <console>:78\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[12] at filter at <console>:78"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// taille par défaut des vecteurs Word2Vec\n",
    "val vectSize = 100\n",
    "\n",
    "// lecture du fichier de tweets dans un RDD (item = ligne)\n",
    "val sentences = sc.textFile(\"/home/user/Documents/UASB03/comment_fr_filtre.csv\")\n",
    "\n",
    "// calcul des représentations Word2Vec des tweets\n",
    "val sent2vec = sentences.filter(sentence => sentence.length >= 1)\n",
    "    .map(sentence => sentence.toLowerCase.split(\"\\\\W+\"))\n",
    "    .map(wordSeq => {\n",
    "        var vSum = Vectors.zeros(vectSize)\n",
    "        var vNb = 0\n",
    "        wordSeq.foreach { word =>\n",
    "            if(!(bStopWords.value)(word) & (word.length >= 2)) {\n",
    "                bVectors.value.get(word).foreach { v =>\n",
    "                    vSum = add(v, vSum)\n",
    "                    vNb += 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if (vNb != 0) {\n",
    "            vSum = scalarMultiply(1.0 / vNb, vSum)\n",
    "        }\n",
    "        vSum\n",
    "    }).filter(vec => Vectors.norm(vec, 1.0) > 0.0).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 2) / 2]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "341575"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2vec.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.10803462937474251,-0.14129161006874508,-0.006262904653946558,-0.08404038701620366,-0.05322896171775129,0.1742613274190161,-0.024228291172120307,-0.06793791893869638,-0.03040544000557727,-0.14900542309300766,0.2211357206106186,0.10082477786474757,-0.07490626650138034,0.0561821475211117,0.030181712988350123,0.1702256882821934,0.11139468455480205,0.035148729363249406,0.04694235697388649,0.16088787135150698,-0.10154435968272284,-0.10311198253960659,0.019933202924827732,0.0144196022560613,-0.020825731257597603,-0.010888704823123084,0.1343119005776114,0.17172166736175615,0.08000474216209517,0.11267615254554483,-0.14040807634592056,0.07251732092764641,-0.031084637675020427,-0.03833507539497481,0.13601658182839552,0.015134393134050898,0.06552158637593189,-0.04657607649763425,0.004045514182911979,-0.12908230142460927,0.09264796930882666,0.08443950046785176,-0.005131173309766584,-0.07981973265608151,-0.0939930412504408,0.031460326371921435,0.02567866216931078,0.08713952451944351,-0.09770151269104745,0.047912989691313766,-0.07097731696234809,0.14086116560631326,-0.20080503733414742,-0.010106806125905778,0.1115985359582636,0.1142281074490812,0.09236186121900876,0.0625546384188864,0.06135144405480888,-0.08474319169504775,-0.04844147556771834,-0.10666316602793004,-0.033756134747010134,0.10314525663852692,-0.020457395662864048,-0.06461158020344251,0.014702183918820486,-0.004180398666196399,-0.06562485504481527,-2.613208360142178E-4,0.010742589210470516,0.06811707384056515,-0.02507288712594244,0.04928788691500408,0.14406048672066793,0.07318157826860745,-0.0053936210460960865,0.045095457384983696,0.01669338583532307,-0.05790910290347205,0.00736718624830246,-0.01268688268545601,0.004471425794892841,0.19698026031255722,-0.08396040379173225,0.03767106433709462,-0.05850133299827576,-0.12321483988004425,0.0435418596284257,0.02547024516388774,-0.01695011763109101,0.01016514432720012,-0.07732523594879441,0.027995065889424745,-0.11383678205311298,-0.054239760152995586,-0.03363759650124444,-0.24157686697112188,0.08789268906952606,0.04237108062564705], [0.08269812995567918,-0.03893242105841637,-0.03934691324830056,0.06692634113132954,-0.10934223297517748,0.10747977942228318,-0.05050090476870537,-0.062276392430067065,0.04380243951454759,-0.1276474179700017,0.09120385572314263,0.08096112534403802,-0.026522314548492434,0.21592574659734964,0.07400571033358574,0.08730876022018492,0.0114583196118474,-0.05693200007081032,0.11903788037598134,-0.21094826590269805,0.02678361460566521,-0.0800238024443388,0.2031991869211197,0.0037592872977256775,-0.03298938390798867,-0.07339037954807281,-0.03665618076920509,-0.07438174858689309,-0.01117522306740284,-0.038033637776970865,-0.041058030724525456,-0.03321306705474854,-0.05534033924341202,0.07783646062016487,0.16766209062188864,-0.055672325566411024,-0.040254279226064685,0.05148765873163939,0.08629854414612055,-0.07013101205229759,-0.016369936615228654,-0.00775295626372099,0.015105609968304635,-0.052046220004558566,-0.07049209848046303,0.045462961937300865,0.03413061611354351,0.15263231843709946,-0.036156984791159634,-0.07879778146743775,0.007535883737728,0.10797196403145791,-0.07061243616044521,0.1225069984793663,0.1281475804746151,0.06702472046017648,0.02276918347924948,-0.0805998407304287,0.03095693187788129,-0.06967614889144898,-0.13853366672992706,-0.10762759745121003,-0.12137300074100495,0.00429684054106474,0.044444715790450576,-0.06603899244219065,-0.033901661075651644,0.06758314399048686,-0.11904921047389508,-0.07864973675459624,0.11740614101290703,0.05224760733544827,-0.11633861437439919,-0.05610742345452309,0.011242173612117767,0.05184430256485939,0.0022370487451553347,-0.04894540021196008,0.026091338554397228,0.1480571284890175,-0.01978472284972668,0.09726201687008143,0.06282157227396966,0.1790898126550019,0.014531690534204245,-0.041864719800651075,-0.02057650573551655,-0.08719909563660622,-0.12917057126760484,0.20815063007175924,-0.04633565098047257,-0.05566946864128113,-0.11733072325587274,0.04885481856763363,-0.04343800097703934,0.05854172557592392,-0.027593233529478314,-0.18003327548503878,0.08781931176781654,0.19160651080310345]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2vec.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 225:>                                                        (0 + 2) / 2]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nbClusters = 20\n",
       "nbIterations = 200\n",
       "clustering = org.apache.spark.mllib.clustering.KMeansModel@474b5691\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.mllib.clustering.KMeansModel@474b5691"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nbClusters = 20\n",
    "val nbIterations = 200\n",
    "val clustering = KMeans.train(sent2vec, nbClusters, nbIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " metro (0,687), o’hare (0,571), zubiarte (0,558), déraille (0,555), smartbike (0,554),\n",
      " isabelle (0,890), monique (0,884), sophie (0,883), hélène (0,882), catherine (0,881),\n",
      " barillerie (0,724), restaurant (0,714), quartier (0,709), promenade (0,707), herbouville (0,697),\n",
      " strive (0,946), tūmatauenga (0,943), honesty (0,942), often (0,939), took (0,938),\n",
      " envolé (0,660), plaisanter (0,641), souriante (0,641), nonchalant (0,637), rondement (0,633),\n",
      " parfait (0,999), tourment (0,645), adorable (0,642), bavard (0,639), rêvé (0,625),\n",
      " repense (0,841), déshabillée (0,833), bourly (0,832), culpabiliser (0,825), minuteur (0,813),\n",
      " recommande (0,979), réaffirme (0,764), l’immunité (0,763), effectivité (0,759), constitutionnellement (0,732),\n",
      " super (0,954), géant (0,666), saiyan (0,660), ninja (0,635), petz (0,608),\n",
      " tres (0,912), vientos (0,736), concierto (0,719), amor (0,710), palabras (0,708),\n",
      " balsam (0,889), mckillip (0,883), begley (0,879), tallulah (0,870), mantovani (0,866),\n",
      " ashikabi (0,861), méritait (0,847), exagérer (0,843), minuteur (0,837), comprenne (0,823),\n",
      " tres (1,000), árbol (0,776), concierto (0,765), ediciones (0,759), amor (0,753),\n",
      " d’espace (0,789), décent (0,777), informatisation (0,775), mezzadro (0,772), inhérent (0,767),\n",
      " bondée (0,641), repense (0,632), entrain (0,632), envolé (0,629), nonchalant (0,625),\n",
      " top (0,994), valign (0,822), meteors (0,736), hot (0,704), airplay (0,688),\n",
      " accueil (0,951), chaleureux (0,646), guichet (0,610), fréquentation (0,605), public (0,604),\n",
      " nermal (0,759), eternel (0,757), arlène (0,755), accro (0,730), abigaïl (0,719),\n",
      " bourly (0,775), parpaing (0,772), repense (0,771), promener (0,753), sereine (0,750),\n",
      " claude (0,897), philippe (0,896), dorny (0,888), gérard (0,885), marc (0,882),\n"
     ]
    }
   ],
   "source": [
    "clustering.clusterCenters.foreach(clusterCenter => {\n",
    "    w2vModel.findSynonyms(clusterCenter,5).foreach(synonym => print(\" %s (%5.3f),\"\n",
    "            .format(synonym._1, synonym._2)))\n",
    "    println()\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
