{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNAM UASB03 - CERTIFICATION ANALYSE DE DONNEES MASSIVES\n",
    "## Projet d'analyse de sentiment sur les commentaires Airbnb en français\n",
    "\n",
    "***\n",
    "Notebook Scala de création des modèles Word2Vec\n",
    "\n",
    "sur les 2 corpus vectorisations précédentes :\n",
    "- Word2Vec Corpus 1 :  extraction wikipédia à fin Juin enrichi du corpus des commentaires AirBnb en langue française\n",
    "- Word2Vec Corpus 2 : corpus constitué des commentaires AirBnb en langue française\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.feature.{Word2Vec, Word2VecModel}\n",
    "\n",
    "val input = sc.textFile(\"Data/frwiki_formate3.txt\").map(line => line.split(\" \").toSeq)\n",
    "val word2vec = new Word2Vec()\n",
    "val model = word2vec.fit(input)\n",
    "\n",
    "// Sauvegarde du modèle\n",
    "model.save(sc, \"modele/Word2VecFR_complet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 2) / 2]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "input = MapPartitionsRDD[2] at map at <console>:29\n",
       "word2vec = org.apache.spark.mllib.feature.Word2Vec@29eb5736\n",
       "model = org.apache.spark.mllib.feature.Word2VecModel@4ec519df\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.mllib.feature.Word2VecModel@4ec519df"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val input = sc.textFile(\"Data/corpus_commentaire.csv\").map(line => line.split(\" \").toSeq)\n",
    "val word2vec = new Word2Vec()\n",
    "val model = word2vec.fit(input)\n",
    "\n",
    "// Sauvegarde du modèle\n",
    "model.save(sc, \"modele/Word2VecFR_comment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cartier 0.8653009533882141\n",
      "secteur 0.733642041683197\n",
      "quatier 0.7191113829612732\n",
      "12eme 0.6054402589797974\n",
      "populaire 0.5925427079200745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "synonyms = Array((cartier,0.8653009533882141), (secteur,0.733642041683197), (quatier,0.7191113829612732), (12eme,0.6054402589797974), (populaire,0.5925427079200745))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(cartier,0.8653009533882141), (secteur,0.733642041683197), (quatier,0.7191113829612732), (12eme,0.6054402589797974), (populaire,0.5925427079200745)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val synonyms = model.findSynonyms(\"quartier\", 5)\n",
    "\n",
    "for((synonym, cosineSimilarity) <- synonyms) {\n",
    "  println(s\"$synonym $cosineSimilarity\")\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
